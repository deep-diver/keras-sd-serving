{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep-diver/keras-sd-serving/blob/main/tf_serving_sd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deviates from the original installation instructions.\n",
        "# https://issuemode.com/issues/tensorflow/serving/92945160\n",
        "!wget 'http://storage.googleapis.com/tensorflow-serving-apt/pool/tensorflow-model-server-universal-2.8.0/t/tensorflow-model-server-universal/tensorflow-model-server-universal_2.8.0_all.deb'\n",
        "!dpkg -i tensorflow-model-server-universal_2.8.0_all.deb"
      ],
      "metadata": {
        "id": "GJ4wOrLBySVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install apt-transport-https curl gnupg\n",
        "!curl -fsSL https://bazel.build/bazel-release.pub.gpg | gpg --dearmor > bazel.gpg\n",
        "!mv bazel.gpg /etc/apt/trusted.gpg.d/\n",
        "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
        "!apt update && apt install bazel"
      ],
      "metadata": {
        "id": "WNufPoBSgGJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aBX296NLfVxu",
        "outputId": "cce199f0-1928-4a63-8007-3de18db2d973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'keras-cv'...\n",
            "remote: Enumerating objects: 6010, done.\u001b[K\n",
            "remote: Counting objects: 100% (239/239), done.\u001b[K\n",
            "remote: Compressing objects: 100% (173/173), done.\u001b[K\n",
            "remote: Total 6010 (delta 124), reused 134 (delta 57), pack-reused 5771\u001b[K\n",
            "Receiving objects: 100% (6010/6010), 8.95 MiB | 18.60 MiB/s, done.\n",
            "Resolving deltas: 100% (3811/3811), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/keras-team/keras-cv.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd keras-cv"
      ],
      "metadata": {
        "id": "B9hUWhBzf7si",
        "outputId": "bff09998-afa0-412c-9881-83e5fe77abd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/keras-cv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout tags/v0.3.5 -b dev\n",
        "\n",
        "!python3 build_deps/configure.py\n",
        "\n",
        "!bazel build build_pip_pkg\n",
        "!bazel-bin/build_pip_pkg wheels"
      ],
      "metadata": {
        "id": "g9InCAtff5Ho",
        "outputId": "fffbdfdf-32f8-46ad-8e70-07c244e03f80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Switched to a new branch 'dev'\n",
            "\n",
            "Configuring KerasCV to be built from source...\n",
            "> Building only CPU ops\n",
            "\n",
            "Build configurations successfully written to .bazelrc :\n",
            "\n",
            "build --action_env TF_HEADER_DIR=\"/usr/local/lib/python3.8/dist-packages/tensorflow/include\"\n",
            "build --action_env TF_SHARED_LIBRARY_DIR=\"/usr/local/lib/python3.8/dist-packages/tensorflow\"\n",
            "build --action_env TF_SHARED_LIBRARY_NAME=\"libtensorflow_framework.so.2\"\n",
            "build --action_env TF_CXX11_ABI_FLAG=\"1\"\n",
            "build --action_env TF_CPLUSPLUS_VER=\"c++14\"\n",
            "build --spawn_strategy=standalone\n",
            "build --strategy=Genrule=standalone\n",
            "build  --experimental_repo_remote_exec\n",
            "build -c opt\n",
            "build --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=\"1\n",
            "build --copt=-mavx\n",
            "build --cxxopt=-std=c++14\n",
            "build --host_cxxopt=-std=c++14\n",
            "\n",
            "Extracting Bazel installation...\n",
            "Starting local Bazel server and connecting to it...\n",
            "WARNING: ignoring LD_PRELOAD in environment.\n",
            "\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (4 packages loaded, 5 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (6 packages loaded, 11 targets configured)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (10 packages loaded, 323 targets configured\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (10 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @bazel_tools//tools/jdk\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (10 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @bazel_tools//tools/jdk ... (3 packages)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (13 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @remotejdk18_win_arm64_toolchain_config_repo// ... (20 \\\n",
            "packages)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (30 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @local_config_sh// ... (4 packages)\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (34 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @local_jdk//\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (34 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @local_jdk//\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (34 packages loaded, 324 targets configured\\\n",
            ")\n",
            "    currently loading: @local_jdk//\n",
            "    Fetching repository @rules_java; starting\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (35 packages loaded, 438 targets configured\\\n",
            ")\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0m/root/.cache/bazel/_bazel_root/2dedc8f50476da95b72ee4dbf842f708/external/bazel_tools/platforms/BUILD:89:6: in alias rule @bazel_tools//platforms:windows: Constraints from @bazel_tools//platforms have been removed. Please use constraints from @platforms repository embedded in Bazel, or preferably declare dependency on https://github.com/bazelbuild/platforms. See https://github.com/bazelbuild/bazel/issues/8622 for details.\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0m/root/.cache/bazel/_bazel_root/2dedc8f50476da95b72ee4dbf842f708/external/bazel_tools/platforms/BUILD:89:6: Analysis of target '@bazel_tools//platforms:windows' failed\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0m/content/keras-cv/keras_cv/custom_ops/BUILD:24:10: errors encountered resolving select() keys for //keras_cv/custom_ops:_keras_cv_custom_ops.so\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[31m\u001b[1mERROR: \u001b[0mAnalysis of target '//:build_pip_pkg' failed; build aborted: \n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 12.297s\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mAnalyzing:\u001b[0m target //:build_pip_pkg (38 packages loaded, 564 targets configured\\\n",
            ")\n",
            "\u001b[31m\u001b[1mFAILED:\u001b[0m Build did NOT complete successfully (38 packages loaded, 564 targets c\\\n",
            "onfigured)\n",
            "    Fetching repository @local_config_cc; starting\n",
            "\u001b[0m/bin/bash: bazel-bin/build_pip_pkg: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/keras-cv/wheels/keras_cv-*.whl"
      ],
      "metadata": {
        "id": "7tA-Jfc_gipM",
        "outputId": "f49bb702-4d28-45b1-ab0c-f1e316fe5806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Requirement '/content/keras-cv/wheels/keras_cv-*.whl' looks like a filename, but the file does not exist\u001b[0m\n",
            "\u001b[31mERROR: keras_cv-*.whl is not a valid wheel filename.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import base64\n",
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "bN8bj-t7fX9M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras_cv.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5zFVAaFPfYNK",
        "outputId": "003d58b0-e59f-4f13-a584-24b94cecec8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv.models.stable_diffusion.text_encoder import TextEncoder\n",
        "from keras_cv.models.stable_diffusion.diffusion_model import DiffusionModel\n",
        "from keras_cv.models.stable_diffusion.decoder import Decoder"
      ],
      "metadata": {
        "id": "OEPKzZc8iaLx",
        "outputId": "074f1346-676a-4195-c65d-66a0a81f7bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-272784cbca3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiffusion_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiffusionModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstable_diffusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_cv'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_PROMPT_LENGTH = 77\n",
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        " \n",
        "text_encoder = TextEncoder(MAX_PROMPT_LENGTH)\n",
        "diffusion_model = DiffusionModel(IMG_HEIGHT, IMG_WIDTH, MAX_PROMPT_LENGTH)\n",
        "decoder = Decoder(IMG_HEIGHT, IMG_WIDTH)"
      ],
      "metadata": {
        "id": "YYyKkH6ki3NV",
        "outputId": "ac78dc74-5491-437d-8418-34ab7e078a30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 4s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 66s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder_weights_fpath = keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\",\n",
        "    file_hash=\"4789e63e07c0e54d6a34a29b45ce81ece27060c499a709d556c7755b42bb0dc4\",\n",
        ")\n",
        "diffusion_model_weights_fpath = keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\",\n",
        "    file_hash=\"8799ff9763de13d7f30a683d653018e114ed24a6a819667da4f5ee10f9e805fe\",\n",
        ")\n",
        "decoder_weights_fpath = keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\",\n",
        "    file_hash=\"ad350a65cc8bc4a80c8103367e039a3329b4231c2469a1093869a345f55b1962\",\n",
        ")"
      ],
      "metadata": {
        "id": "M0eNbAGojNh4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder.load_weights(text_encoder_weights_fpath)\n",
        "diffusion_model.load_weights(diffusion_model_weights_fpath)\n",
        "decoder.load_weights(decoder_weights_fpath)"
      ],
      "metadata": {
        "id": "y6GHaFWTlMvr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras_cv.models.stable_diffusion.clip_tokenizer import SimpleTokenizer\n",
        "tokenizer = SimpleTokenizer()\n",
        "\n",
        "def _get_pos_ids():\n",
        "    return tf.convert_to_tensor([list(range(MAX_PROMPT_LENGTH))], dtype=tf.int32)\n",
        "\n",
        "def encode_text(prompt):\n",
        "    \"\"\"Encodes a prompt into a latent text encoding.\n",
        "    The encoding produced by this method should be used as the\n",
        "    `encoded_text` parameter of `StableDiffusion.generate_image`. Encoding\n",
        "    text separately from generating an image can be used to arbitrarily\n",
        "    modify the text encoding priot to image generation, e.g. for walking\n",
        "    between two prompts.\n",
        "    Args:\n",
        "        prompt: a string to encode, must be 77 tokens or shorter.\n",
        "    Example:\n",
        "    ```python\n",
        "    from keras_cv.models import StableDiffusion\n",
        "    model = StableDiffusion(img_height=512, img_width=512, jit_compile=True)\n",
        "    encoded_text  = model.encode_text(\"Tacos at dawn\")\n",
        "    img = model.generate_image(encoded_text)\n",
        "    ```\n",
        "    \"\"\"\n",
        "    # Tokenize prompt (i.e. starting context)\n",
        "    inputs = tokenizer.encode(prompt)\n",
        "    if len(inputs) > MAX_PROMPT_LENGTH:\n",
        "        raise ValueError(\n",
        "            f\"Prompt is too long (should be <= {MAX_PROMPT_LENGTH} tokens)\"\n",
        "        )\n",
        "    phrase = inputs + [49407] * (MAX_PROMPT_LENGTH - len(inputs))\n",
        "    phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)\n",
        "\n",
        "    context = text_encoder.predict_on_batch([phrase, _get_pos_ids()])\n",
        "\n",
        "    return context\n",
        "\n",
        "encoded_text = encode_text(\"photograph of an astronaut riding a horse\")"
      ],
      "metadata": {
        "id": "73PD3ikjlV2L",
        "outputId": "900c2cae-9a2b-44cd-fb97-cbbb45793ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer.encode(\"photograph of an astronaut riding a horse\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKx7FntVwCOv",
        "outputId": "ca017acd-5084-4c77-97ff-d119993da514"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[49406, 8853, 539, 550, 18376, 6765, 320, 4558, 49407]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = inputs + [49407] * (MAX_PROMPT_LENGTH - len(inputs))\n",
        "phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)\n",
        "phrase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD2dk87NwKsR",
        "outputId": "22122d8c-5bf0-4f79-ef2e-6813a2e1f85a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 77), dtype=int32, numpy=\n",
              "array([[49406,  8853,   539,   550, 18376,  6765,   320,  4558, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,\n",
              "        49407, 49407, 49407, 49407, 49407]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yowJTRcdlqPv",
        "outputId": "cdfa8110-f977-48be-ef18-dc9d9a2a4760"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.3883766 ,  0.02294356, -0.05219662, ..., -0.48988292,\n",
              "         -0.30660194,  0.06745391],\n",
              "        [ 0.1156525 ,  0.4144913 ,  2.3049333 , ..., -1.7711414 ,\n",
              "         -1.0141486 , -0.9208659 ],\n",
              "        [-0.4335628 , -0.09044406,  0.722898  , ...,  0.8755375 ,\n",
              "         -1.0948254 , -0.7246346 ],\n",
              "        ...,\n",
              "        [-3.080411  , -0.19198483, -0.33464575, ...,  0.5393776 ,\n",
              "         -0.15574259,  0.60614014],\n",
              "        [-3.0885706 , -0.24322483, -0.3512005 , ...,  0.5685484 ,\n",
              "         -0.15004434,  0.5980401 ],\n",
              "        [-3.0169518 , -0.24591564, -0.30276614, ...,  0.5613408 ,\n",
              "         -0.10421933,  0.5855357 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Encoder in SavedModel\n",
        "\n",
        "Assumes that tokens are prepared to be passed to the model with `SimpleTokenizer`"
      ],
      "metadata": {
        "id": "bh7F8Vgpm6__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoder.inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l691SMIYnwjn",
        "outputId": "5c334100-e593-4693-c2a9-585b15a138eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 77) dtype=int32 (created by layer 'tokens')>,\n",
              " <KerasTensor: shape=(None, 77) dtype=int32 (created by layer 'positions')>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ›‘ can't make concrete function, current codes simply calls the model itself without concrete function. need to investigate if this is an error"
      ],
      "metadata": {
        "id": "sR2dOtp9_57u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "m_call = tf.function(text_encoder.call).get_concrete_function(\n",
        "        tf.TensorSpec(\n",
        "            shape=[1, 77], dtype=tf.int32, name='token'\n",
        "        ),\n",
        "        tf.TensorSpec(\n",
        "            shape=[1, 77], dtype=tf.int32, name='positions'\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "jzkflE3Y-WDP",
        "outputId": "f6fee9d2-4514-4a99-8e06-f5c278b604d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-e44773e70fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m m_call = tf.function(text_encoder.call).get_concrete_function(\n\u001b[0m\u001b[1;32m      2\u001b[0m         tf.TensorSpec(\n\u001b[1;32m      3\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m77\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'token'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         ),\n\u001b[1;32m      5\u001b[0m         tf.TensorSpec(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;31m# Implements GenericFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1240\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1217\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 785\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    786\u001b[0m             *args, **kwds))\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2478\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_internal_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0mx_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mx_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Could not compute output '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m       \u001b[0moutput_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 459, in call  *\n        inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/functional.py\", line 605, in _run_internal_graph  **\n        assert x_id in tensor_dict, 'Could not compute output ' + str(x)\n\n    AssertionError: Could not compute output KerasTensor(type_spec=TensorSpec(shape=(None, 77, 768), dtype=tf.float32, name=None), name='layer_normalization_24/batchnorm/add_1:0', description=\"created by layer 'layer_normalization_24'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "id": "Oa6g2e0uHQ41",
        "outputId": "47449343-ba37-4c67-9c87-cdaa2c651d02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv.models.stable_diffusion.constants import _UNCONDITIONAL_TOKENS\n",
        "\n",
        "signature_dict = { \"tokens\": tf.TensorSpec(shape=[], dtype=tf.int32, name=\"tokens\"),\n",
        "                   \"batch_size\": tf.TensorSpec(shape=[], dtype=tf.int32, name=\"batch_size\")}\n",
        "\n",
        "def model_exporter(model: tf.keras.Model):\n",
        "    MAX_PROMPT_LENGTH = 77\n",
        "    pos_ids = tf.convert_to_tensor([list(range(MAX_PROMPT_LENGTH))], dtype=tf.int32)\n",
        "\n",
        "    @tf.function(input_signature=[signature_dict])\n",
        "    def serving_fn(string_input):\n",
        "        batch_size = string_input[\"batch_size\"]\n",
        "\n",
        "        # context\n",
        "        encoded_text = model([string_input['tokens'], pos_ids])\n",
        "        encoded_text = tf.squeeze(encoded_text)\n",
        "\n",
        "        if encoded_text.shape.rank == 2:\n",
        "            encoded_text = tf.repeat(\n",
        "                tf.expand_dims(encoded_text, axis=0), batch_size, axis=0\n",
        "            )\n",
        "        context = encoded_text\n",
        "\n",
        "        # unconditional context\n",
        "        unconditional_tokens = tf.convert_to_tensor([_UNCONDITIONAL_TOKENS], dtype=tf.int32)\n",
        "        unconditional_context = model([unconditional_tokens, pos_ids])        \n",
        "\n",
        "        unconditional_context = tf.repeat(\n",
        "            unconditional_context, batch_size, axis=0\n",
        "        )\n",
        "        return {\"context\": encoded_text, \"unconditional_context\": unconditional_context}\n",
        "\n",
        "    return serving_fn"
      ],
      "metadata": {
        "id": "L440yXr6nSCp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(\n",
        "    text_encoder,\n",
        "    \"./text_encoder/1/\",\n",
        "    signatures={\"serving_default\": model_exporter(text_encoder)},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hrwfz1ihmexV",
        "outputId": "889545e9-4c04-42a5-b155-43db35c328f8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 77) for input KerasTensor(type_spec=TensorSpec(shape=(None, 77), dtype=tf.int32, name='tokens'), name='tokens', description=\"created by layer 'tokens'\"), but it was called on an input with incompatible shape ().\n",
            "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, layer_normalization_layer_call_fn while saving (showing 5 of 220). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir text_encoder/1/ --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL-cCWSOrM7X",
        "outputId": "3d7e1f2a-e3f6-40d6-9547-86427468a8d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['batch_size'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: ()\n",
            "      name: serving_default_batch_size:0\n",
            "  inputs['tokens'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: ()\n",
            "      name: serving_default_tokens:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['context'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 77, 768)\n",
            "      name: StatefulPartitionedCall:0\n",
            "  outputs['unconditional_context'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 77, 768)\n",
            "      name: StatefulPartitionedCall:1\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the encoder SavedModel"
      ],
      "metadata": {
        "id": "6PLbzHh6xrK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = SimpleTokenizer()\n",
        "prompt = \"photograph of an astronaut riding a horse\"\n",
        "inputs = tokenizer.encode(prompt)\n",
        "\n",
        "phrase = inputs + [49407] * (MAX_PROMPT_LENGTH - len(inputs))\n",
        "# phrase = tf.convert_to_tensor([phrase], dtype=tf.int32)"
      ],
      "metadata": {
        "id": "QK8PQUjusdxn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8501 \\\n",
        "  --model_name=text_encoder \\\n",
        "  --model_base_path=/content/text_encoder >server.log 2>&1"
      ],
      "metadata": {
        "id": "WRT_2VLnx0OT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat server.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--FoOsNL2lV1",
        "outputId": "13d1c683-0b30-45f0-f892-4c988c92c00e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "[evhttp_server.cc : 230] NET_LOG: Couldn't bind to port 8501\n",
            "[evhttp_server.cc : 63] NET_LOG: Server has not been terminated. Force termination now.\n",
            "[evhttp_server.cc : 265] NET_LOG: Server is not running ...\n",
            "2022-12-21 01:41:29.223397: E tensorflow_serving/model_servers/server.cc:440] Failed to start HTTP Server at localhost:8501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsof -i -P -n | grep LISTEN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcC6OMV9yAS_",
        "outputId": "6b993251-03c2-4a77-ec62-f0de0433b343"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "node          7 root   21u  IPv6  19148      0t0  TCP *:8080 (LISTEN)\n",
            "kernel_ma    35 root    7u  IPv4  18795      0t0  TCP 172.28.0.12:6000 (LISTEN)\n",
            "colab-fil    60 root    5u  IPv4  17804      0t0  TCP *:3453 (LISTEN)\n",
            "colab-fil    60 root    6u  IPv6  17805      0t0  TCP *:3453 (LISTEN)\n",
            "jupyter-n    82 root    6u  IPv4  17873      0t0  TCP 172.28.0.12:9000 (LISTEN)\n",
            "python3    1342 root   23u  IPv4  41610      0t0  TCP 127.0.0.1:43909 (LISTEN)\n",
            "python3    1385 root    3u  IPv4  41978      0t0  TCP 127.0.0.1:22711 (LISTEN)\n",
            "python3    1385 root    4u  IPv4  41979      0t0  TCP 127.0.0.1:33185 (LISTEN)\n",
            "python3    1385 root    9u  IPv4  42210      0t0  TCP 127.0.0.1:41729 (LISTEN)\n",
            "java       2720 root   19u  IPv4  51865      0t0  TCP 127.0.0.1:41333 (LISTEN)\n",
            "tensorflo  8136 root    5u  IPv4 199864      0t0  TCP *:8500 (LISTEN)\n",
            "tensorflo  8136 root   12u  IPv4 199872      0t0  TCP *:8501 (LISTEN)\n",
            "tensorflo 23870 root    5u  IPv4 411892      0t0  TCP *:8500 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": [{\"tokens\": phrase, \"batch_size\": 1}]})\n",
        "print(\"Data: {} ... {}\".format(data[:50], data[len(data) - 52 :]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DISvHPcTyBzW",
        "outputId": "0526ce83-e6e6-44e8-e2a3-b1cd31dda0d5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: {\"signature_name\": \"serving_default\", \"instances\": ... 407, 49407, 49407, 49407, 49407], \"batch_size\": 1}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post(\n",
        "    \"http://localhost:8501/v1/models/text_encoder:predict\", data=data, headers=headers\n",
        ")"
      ],
      "metadata": {
        "id": "E3xmnbfn20nc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_response = json.loads(json_response.text)"
      ],
      "metadata": {
        "id": "4xu5WGyZIWzz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "context = np.array(json_response['predictions'][0]['context'])\n",
        "print(context.shape)\n",
        "print(context)"
      ],
      "metadata": {
        "id": "yrdXm56YJE6J",
        "outputId": "07161d29-5e61-4942-af9f-00795212d7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77, 768)\n",
            "[[-0.38837659  0.02294353 -0.05219658 ... -0.48988289 -0.306602\n",
            "   0.06745389]\n",
            " [ 0.11565271  0.41449198  2.30493188 ... -1.77114189 -1.01414979\n",
            "  -0.92086858]\n",
            " [-0.43356392 -0.09044611  0.72289908 ...  0.87553692 -1.09482622\n",
            "  -0.72463357]\n",
            " ...\n",
            " [-3.0804112  -0.19198492 -0.33464611 ...  0.53937751 -0.15574202\n",
            "   0.60613984]\n",
            " [-3.08857059 -0.24322379 -0.3512004  ...  0.56854761 -0.15004414\n",
            "   0.59803879]\n",
            " [-3.01695275 -0.24591462 -0.30276683 ...  0.5613395  -0.10421869\n",
            "   0.58553594]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unconditional_context = np.array(json_response['predictions'][0]['unconditional_context'])\n",
        "print(unconditional_context.shape)\n",
        "print(unconditional_context)"
      ],
      "metadata": {
        "id": "ubin8_Q6Iz8y",
        "outputId": "1c2fad0c-5c40-40f2-e8bb-a314ad253fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(77, 768)\n",
            "[[-0.38837659  0.02294353 -0.05219658 ... -0.48988289 -0.306602\n",
            "   0.06745389]\n",
            " [-0.3711203  -1.44965601 -0.34011435 ...  0.94886273  0.18672347\n",
            "  -1.10343707]\n",
            " [-0.5107379  -1.46287918 -0.29255477 ...  1.04190361  0.07005903\n",
            "  -1.02841437]\n",
            " ...\n",
            " [ 0.50059444 -0.95523065 -0.66102648 ...  1.6012907  -1.06221962\n",
            "  -0.21908539]\n",
            " [ 0.49881172 -0.94508839 -0.66560739 ...  1.64667022 -1.0858376\n",
            "  -0.20878072]\n",
            " [ 0.4923487  -0.81244445 -0.49119091 ...  1.61076951 -1.01735508\n",
            "  -0.2483795 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diffusion Model in SavedModel"
      ],
      "metadata": {
        "id": "5uaJif4j44pz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdYyl9LNbsxD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.constant(_ALPHAS_CUMPROD)"
      ],
      "metadata": {
        "id": "X0ViEXwIb7m1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[0]"
      ],
      "metadata": {
        "id": "aF9T1kHQcCgu",
        "outputId": "d3ff4dc6-e492-4927-e339-741c94201628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.99915>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras_cv.models.stable_diffusion.diffusion_model import DiffusionModel\n",
        "\n",
        "MAX_PROMPT_LENGTH = 77\n",
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "\n",
        "diffusion_model = DiffusionModel(IMG_HEIGHT, IMG_WIDTH, MAX_PROMPT_LENGTH)\n",
        "diffusion_model_weights_fpath = keras.utils.get_file(\n",
        "    origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\",\n",
        "    file_hash=\"8799ff9763de13d7f30a683d653018e114ed24a6a819667da4f5ee10f9e805fe\",\n",
        ")\n",
        "diffusion_model.load_weights(diffusion_model_weights_fpath)"
      ],
      "metadata": {
        "id": "BYc-dzLZP-Xp",
        "outputId": "50702fa4-1cf2-44a2-8116-bb978b69defc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 78s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diffusion_model.inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_5a-98I3IAj",
        "outputId": "dd5674e5-b00f-40fb-9f98-5950bffc8908"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 64, 64, 4) dtype=float32 (created by layer 'input_3')>,\n",
              " <KerasTensor: shape=(None, 320) dtype=float32 (created by layer 'input_2')>,\n",
              " <KerasTensor: shape=(None, 77, 768) dtype=float32 (created by layer 'input_1')>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv.models.stable_diffusion.constants import _ALPHAS_CUMPROD"
      ],
      "metadata": {
        "id": "qQLnvWd-cLJ5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps = tf.range(1, 1000, 1000 // 25)\n",
        "_ALPHAS_CUMPROD_tt = tf.constant(_ALPHAS_CUMPROD)"
      ],
      "metadata": {
        "id": "xK5Iu6-3ccHV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps"
      ],
      "metadata": {
        "id": "F7cgrf_achKX",
        "outputId": "7cdfd332-7505-4b88-88da-183e0b85697a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=int32, numpy=\n",
              "array([  1,  41,  81, 121, 161, 201, 241, 281, 321, 361, 401, 441, 481,\n",
              "       521, 561, 601, 641, 681, 721, 761, 801, 841, 881, 921, 961],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.map_fn(lambda t: _ALPHAS_CUMPROD_tt[t], timesteps, dtype=tf.float32)"
      ],
      "metadata": {
        "id": "Bh-0ey_bcsno"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "dyJrPZiseZ7H",
        "outputId": "89d76a23-9b0d-4a64-a26a-0bc1f9ab07ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
              "array([0.998296  , 0.96087277, 0.9171379 , 0.86737   , 0.81210774,\n",
              "       0.7521434 , 0.6884991 , 0.6223854 , 0.55514455, 0.4881804 ,\n",
              "       0.4228815 , 0.36054322, 0.30229566, 0.24904492, 0.20143245,\n",
              "       0.15981644, 0.12427604, 0.09463691, 0.0705137 , 0.05136392,\n",
              "       0.03654652, 0.02537862, 0.01718517, 0.01133791, 0.00728173],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[:-1]"
      ],
      "metadata": {
        "id": "ZJgD4TZweW9Q",
        "outputId": "b6954a4f-3ec7-4a22-e6e0-2ecfdf40ce98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=float32, numpy=\n",
              "array([0.998296  , 0.96087277, 0.9171379 , 0.86737   , 0.81210774,\n",
              "       0.7521434 , 0.6884991 , 0.6223854 , 0.55514455, 0.4881804 ,\n",
              "       0.4228815 , 0.36054322, 0.30229566, 0.24904492, 0.20143245,\n",
              "       0.15981644, 0.12427604, 0.09463691, 0.0705137 , 0.05136392,\n",
              "       0.03654652, 0.02537862, 0.01718517, 0.01133791], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.concat([[1.0], test[:-1]], 0)"
      ],
      "metadata": {
        "id": "0CG4v4q9eeEv",
        "outputId": "16f3ed16-734a-42af-bdec-65fe5e81b38f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25,), dtype=float32, numpy=\n",
              "array([1.        , 0.998296  , 0.96087277, 0.9171379 , 0.86737   ,\n",
              "       0.81210774, 0.7521434 , 0.6884991 , 0.6223854 , 0.55514455,\n",
              "       0.4881804 , 0.4228815 , 0.36054322, 0.30229566, 0.24904492,\n",
              "       0.20143245, 0.15981644, 0.12427604, 0.09463691, 0.0705137 ,\n",
              "       0.05136392, 0.03654652, 0.02537862, 0.01718517, 0.01133791],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_prev = [1.0] + test[:-1]\n",
        "test_prev"
      ],
      "metadata": {
        "id": "dc05AhSVeNA2",
        "outputId": "bff2bf39-0878-4ca3-a058-c3fad3e8a938",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(24,), dtype=float32, numpy=\n",
              "array([1.998296 , 1.9608728, 1.9171379, 1.86737  , 1.8121078, 1.7521434,\n",
              "       1.6884991, 1.6223854, 1.5551445, 1.4881804, 1.4228815, 1.3605433,\n",
              "       1.3022957, 1.2490449, 1.2014325, 1.1598165, 1.124276 , 1.0946369,\n",
              "       1.0705137, 1.051364 , 1.0365465, 1.0253786, 1.0171852, 1.0113379],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = tf.constant(1)"
      ],
      "metadata": {
        "id": "zKjOBn8jfUNb"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test[i]"
      ],
      "metadata": {
        "id": "tSwWQlEpfWSU",
        "outputId": "c9705e4b-7d79-470d-e265-572e7b2f41d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.96087277>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "\n",
        "signature_dict = { \"context\": tf.TensorSpec(shape=[None, 77, 768], dtype=tf.float32, name=\"context\"),\n",
        "                   \"unconditional_context\": tf.TensorSpec(shape=[None, 77, 768], dtype=tf.float32, name=\"unconditional_context\"),\n",
        "                   \"num_steps\": tf.TensorSpec(shape=[], dtype=tf.int32, name=\"num_steps\"),\n",
        "                   \"batch_size\": tf.TensorSpec(shape=[], dtype=tf.int32, name=\"batch_size\")}\n",
        "\n",
        "def model_exporter(model: tf.keras.Model):\n",
        "    IMG_HEIGHT = 512\n",
        "    IMG_WIDTH = 512\n",
        "    MAX_PROMPT_LENGTH = 77\n",
        "\n",
        "    SEED = None\n",
        "\n",
        "    @tf.function\n",
        "    def _get_timestep_embedding(timestep, batch_size, dim=320, max_period=10000):\n",
        "        half = dim // 2\n",
        "        freqs = tf.math.exp(\n",
        "            -math.log(max_period) * tf.range(0, half, dtype=tf.float32) / half\n",
        "        )\n",
        "        args = tf.convert_to_tensor([timestep], dtype=tf.float32) * freqs\n",
        "        embedding = tf.concat([tf.math.cos(args), tf.math.sin(args)], 0)\n",
        "        embedding = tf.reshape(embedding, [1, -1])\n",
        "        return tf.repeat(embedding, batch_size, axis=0)\n",
        "\n",
        "    @tf.function(input_signature=[signature_dict])\n",
        "    def serving_fn(string_input):\n",
        "        img_height = round(IMG_HEIGHT / 128) * 128\n",
        "        img_width = round(IMG_WIDTH / 128) * 128\n",
        "        unconditional_guidance_scale = 7.5\n",
        "\n",
        "        batch_size = string_input[\"batch_size\"]\n",
        "        num_steps = string_input[\"num_steps\"]\n",
        "\n",
        "        context = string_input[\"context\"]\n",
        "        unconditional_context = string_input[\"unconditional_context\"]\n",
        "\n",
        "        latent = tf.random.normal(\n",
        "            (batch_size, img_height // 8, img_width // 8, 4), seed=SEED\n",
        "        )\n",
        "\n",
        "        timesteps = tf.range(1, 1000, 1000 // num_steps)\n",
        "        _ALPHAS_CUMPROD_t = tf.constant(_ALPHAS_CUMPROD)\n",
        "        alphas = tf.map_fn(lambda t: _ALPHAS_CUMPROD_t[t], timesteps, dtype=tf.float32)\n",
        "        alphas_prev = tf.concat([[1.0], alphas[:-1]], 0)\n",
        "\n",
        "        index = 0\n",
        "        for t in timesteps:\n",
        "          latent_prev = latent\n",
        "          t_emb = _get_timestep_embedding(t, batch_size)\n",
        "          unconditional_latent = model(\n",
        "              [latent, t_emb, unconditional_context]\n",
        "          )\n",
        "          latent = model([latent, t_emb, context])\n",
        "          latent = unconditional_latent + unconditional_guidance_scale * (\n",
        "              latent - unconditional_latent\n",
        "          )\n",
        "          a_t, a_prev = alphas[index], alphas_prev[index]\n",
        "          pred_x0 = (latent_prev - tf.math.sqrt(1 - a_t) * latent) / tf.math.sqrt(a_t)\n",
        "          latent = latent * tf.math.sqrt(1.0 - a_prev) + tf.math.sqrt(a_prev) * pred_x0\n",
        "          index = index + 1\n",
        "\n",
        "        return {\"latent\": latent}\n",
        "\n",
        "    return serving_fn"
      ],
      "metadata": {
        "id": "XloXV_y84_17"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(\n",
        "    diffusion_model,\n",
        "    \"./diffusion_model/1/\",\n",
        "    signatures={\"serving_default\": model_exporter(diffusion_model)},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r88D1nSEA1hW",
        "outputId": "2bf56ba9-96aa-4d5f-afa0-95a3dae00f75"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, group_normalization_2_layer_call_fn, group_normalization_2_layer_call_and_return_conditional_losses while saving (showing 5 of 1320). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!saved_model_cli show --dir diffusion_model/1/ --tag_set serve --signature_def serving_default"
      ],
      "metadata": {
        "id": "mPqn3gp7A6nw",
        "outputId": "992596ff-62c6-4fca-ab0e-afbc7716e8f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The given SavedModel SignatureDef contains the following input(s):\n",
            "  inputs['batch_size'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: ()\n",
            "      name: serving_default_batch_size:0\n",
            "  inputs['context'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 77, 768)\n",
            "      name: serving_default_context:0\n",
            "  inputs['num_steps'] tensor_info:\n",
            "      dtype: DT_INT32\n",
            "      shape: ()\n",
            "      name: serving_default_num_steps:0\n",
            "  inputs['unconditional_context'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 77, 768)\n",
            "      name: serving_default_unconditional_context:0\n",
            "The given SavedModel SignatureDef contains the following output(s):\n",
            "  outputs['latent'] tensor_info:\n",
            "      dtype: DT_FLOAT\n",
            "      shape: (-1, 64, 64, 4)\n",
            "      name: StatefulPartitionedCall:0\n",
            "Method name is: tensorflow/serving/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxRS02SOg7ZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}